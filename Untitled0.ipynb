{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kenjiro1/TACO/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dHhtvfsn0kE0",
        "outputId": "daeac311-cdf5-4bff-84ce-b7e277d05c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 132MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Captura de tela 2025-08-06 220651.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2021563199.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Abre e prepara a imagem, convertendo para RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Captura de tela 2025-08-06 220651.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Captura de tela 2025-08-06 220651.png'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import urllib.request\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "#KENJI\n",
        "url1 = 'https://raw.githubusercontent.com/Kenjiro1/TACO/refs/heads/main/taco-db-aminoacidos-2.csv'\n",
        "url2 = 'https://raw.githubusercontent.com/Kenjiro1/TACO/refs/heads/main/taco-db-aminoacidos.csv'\n",
        "url3 = 'https://raw.githubusercontent.com/Kenjiro1/TACO/refs/heads/main/taco-db-graxos-2.csv'\n",
        "url4 = 'https://raw.githubusercontent.com/Kenjiro1/TACO/refs/heads/main/taco-db-graxos.csv'\n",
        "url5='https://raw.githubusercontent.com/Kenjiro1/TACO/refs/heads/main/taco-db-graxos.csv'\n",
        "url6= 'https://raw.githubusercontent.com/Kenjiro1/TACO/refs/heads/main/taco-db-nutrientes.csv'\n",
        "# pedindo analise para descobrir qual o alimento da imagem\n",
        "model = models.resnet18(weights=True)\n",
        "model.eval()\n",
        "\n",
        "# Transforma a imagem para o formato esperado pelo modelo\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # valores padrão do ImageNet\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "# Abre e prepara a imagem, convertendo para RGB\n",
        "img = Image.open(\"/Captura de tela 2025-08-06 220651.png\").convert('RGB')\n",
        "img_t = preprocess(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "# Faz a previsão\n",
        "with torch.no_grad():\n",
        "    out = model(batch_t)\n",
        "\n",
        "# Carrega os nomes das classes do ImageNet\n",
        "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "class_names_str = urllib.request.urlopen(url).read().decode()\n",
        "class_names = class_names_str.splitlines()\n",
        "\n",
        "\n",
        "# Mostra a previsão mais provável\n",
        "_, index = torch.max(out, 1)\n",
        "identified_food = class_names[index]\n",
        "print(\"Comida identificada:\", identified_food)\n",
        "\n",
        "# Carrega a lista de alimentos com as suas respectivas categorias e informações, carregado do arquivo csv\n",
        "lista_de_comidas = pd.DataFrame(pd.read_csv(\"/nutrition.csv\"))\n",
        "#display(lista_de_comidas.head())\n",
        "\n",
        "# Encontra o alimento inserido pelo usuario na lista de comidas\n",
        "infos = None\n",
        "for food_item in lista_de_comidas['name']:\n",
        "  if identified_food.lower() in food_item.lower():\n",
        "    infos = lista_de_comidas[lista_de_comidas['name'] == food_item]\n",
        "    break  # Para a busca assim que encontrar o primeiro match\n",
        "\n",
        "if infos is not None:\n",
        "    display(infos)\n",
        "else:\n",
        "    print(f\"'{identified_food}' não encontrado na lista de comidas.\")\n",
        "\n",
        "#"
      ]
    }
  ]
}